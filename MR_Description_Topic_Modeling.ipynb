{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b37ef68",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA) for MR Route Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ad140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "valid_states = ['Alabama', 'California', 'Georgia', 'Missouri', 'Illinois', 'Ohio',\n",
    "       'Kentucky', 'Colorado', 'United States', 'Indiana', 'New York',\n",
    "       'Vermont', 'Texas', 'Florida', 'Minnesota', 'Virginia',\n",
    "       'Oklahoma', 'Arkansas', 'Maryland', 'West Virginia',\n",
    "       'Michigan', 'North Carolina', 'Oregon', 'Pennsylvania',\n",
    "       'Washington', 'New Jersey', 'Alaska',\n",
    "       'South Carolina', 'Utah', 'New Hampshire', 'Iowa', 'Louisiana',\n",
    "       'Mississippi', 'Wisconsin',\n",
    "       'South Dakota', 'Wyoming', 'Massachusetts', 'New Mexico',\n",
    "       'Montana', 'Idaho', 'Nevada', 'Arizona',\n",
    "       'Kansas', 'Northeast', 'Southwest', 'Golf Coast', 'Southeast',\n",
    "       'Tennessee', 'Nebraska', 'Delaware', 'Pacific Coast',\n",
    "       'Appalachian Mountains', 'Maine', 'Rhode Island', 'Connecticut',\n",
    "       'North Dakota', 'Hawaii']\n",
    "\n",
    "route_data_RAW = pd.read_csv('route_data_RAW.csv')\n",
    "route_data_RAW['description'] = route_data_RAW.agg(lambda x: f\"{x['scenery_description']}, {x['drive_enjoyment_description']}, {x['tourism_description']}\", axis=1)\n",
    "route_data_RAW.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "STOP_WORDS = STOP_WORDS.union({'ll', 've', 'pron',\n",
    "                                'good','great', 'nice',\n",
    "                                'ride','route','road','rt','roads'\n",
    "                              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c0e5d",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb57422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1,2)\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range,\n",
    "                             stop_words=STOP_WORDS,\n",
    "                            )\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "texts = route_data_RAW.description.values.tolist()\n",
    "processed_text = [analyzer(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d997db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_text)\n",
    "print('Number of unique tokens: {}'.format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(t) for t in processed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56429957",
   "metadata": {},
   "source": [
    "## Initial LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7064c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA model parameters\n",
    "num_topics = 3\n",
    "num_words = 10\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=num_topics, \n",
    "                                            random_state=17, update_every=1,\n",
    "                                            chunksize=1500, \n",
    "                                            passes=5, iterations=10,\n",
    "                                            alpha='asymmetric', eta=1/100,\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics(num_words=num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_document_topics method shows the topics found \n",
    "# in each corpus doc\n",
    "lda_model.get_document_topics(corpus[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts dominant topic (and percentage) for each comment\n",
    "\n",
    "def get_main_topic_df(model, bow, texts):\n",
    "    topic_list = []\n",
    "    percent_list = []\n",
    "    keyword_list = []\n",
    "    \n",
    "    for wc in bow:\n",
    "        topic, percent = sorted(model.get_document_topics(wc), key=lambda x: x[1], reverse=True)[0]\n",
    "        topic_list.append(topic)\n",
    "        percent_list.append(round(percent, 3))\n",
    "        keyword_list.append(' '.join(sorted([x[0] for x in model.show_topic(topic)])))\n",
    "\n",
    "    result_df = pd.concat([pd.Series(topic_list, name='Dominant_topic'), \n",
    "                           pd.Series(percent_list, name='Percent'), \n",
    "                           pd.Series(texts, name='Processed_text'), \n",
    "                           pd.Series(keyword_list, name='Keywords')], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c443f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic_df = get_main_topic_df(lda_model, corpus, processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8598a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(main_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e4bb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "grouped_topics = main_topic_df.groupby('Dominant_topic')\n",
    "grouped_topics.count()['Processed_text'].\\\n",
    "    plot.bar(rot=0).\\\n",
    "    set(title=f'Dominant Topic Frequency in the {len(route_data_RAW)} Descriptions',\n",
    "        ylabel='Topic frequency');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470d5aa",
   "metadata": {},
   "source": [
    "## Representative data\n",
    "\n",
    "What's the \"most representative\" comment we have in the data for each topic?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives = pd.DataFrame()\n",
    "\n",
    "for k in grouped_topics.groups.keys():\n",
    "    representatives = pd.concat([ representatives, \n",
    "                                 grouped_topics.get_group(k).sort_values(['Percent'], ascending=False).head(5)])\n",
    "# representatives\n",
    "for i in range(len(representatives)):\n",
    "    print(f'''\n",
    "        Document: {representatives.index[i]}  \n",
    "        Dominant topic: {representatives.loc[representatives.index[i]]['Dominant_topic']}\\n \n",
    "    ''')\n",
    "    print(texts[representatives.index[i]] + '\\n ------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc72e87",
   "metadata": {},
   "source": [
    "There seem to be two dominant topics in this set of comments. \n",
    "\n",
    "Two types of roads:\n",
    "1. Roads for the RIDE (Topic 0)\n",
    "2. Roads for the VIEW (Topic 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b521d96",
   "metadata": {},
   "source": [
    "## Length of documents in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db9ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_by_topic(topic=0):\n",
    "    d_lens = [len(d) for d in grouped_topics.get_group(topic)['Processed_text']]\n",
    "    plt.hist(d_lens, bins=50)\n",
    "    large = plt.gca().get_ylim()[1]\n",
    "    d_mean = round(np.mean(d_lens), 1)\n",
    "    d_median = np.median(d_lens)\n",
    "    plt.plot([d_mean, d_mean], [0,large], label='Mean = {}'.format(d_mean))\n",
    "    plt.plot([d_median, d_median], [0,large], label='Median = {}'.format(d_median))\n",
    "    plt.legend()\n",
    "    plt.gca().set(xlabel='Document word count', ylabel='Number of documents', xlim=(0, 450), \n",
    "            title='Distribution of Comment Lengths for {} Comments in Topic {}'.format(len(d_lens), topic));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6130a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slider = IntSlider(min=0, max=num_topics-1, step=1, value=0, description='Topic')\n",
    "interact(word_count_by_topic, topic=slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc984e",
   "metadata": {},
   "source": [
    "## Top word distribution per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71500336",
   "metadata": {
    "scrolled": false,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "lda_top_words_index = set()\n",
    "for i in range(lda_model.num_topics):\n",
    "    lda_top_words_index = lda_top_words_index.union([k for (k,v) in lda_model.get_topic_terms(i)])\n",
    "\n",
    "\n",
    "words_we_care_about = [{dictionary[tup[0]]: tup[1] for tup in lst if tup[0] in lda_top_words_index} \n",
    "                       for lst in corpus]\n",
    "\n",
    "lda_top_words_df = pd.DataFrame(words_we_care_about).fillna(0).astype(int).sort_index(axis=1)\n",
    "lda_top_words_df['Cluster'] = main_topic_df['Dominant_topic']\n",
    "\n",
    "(\n",
    "    lda_top_words_df\n",
    "    .groupby('Cluster').sum().transpose()\n",
    "    .plot.bar(figsize=(15, 5), width=0.7)\n",
    "    .set(ylabel='Word frequency', \n",
    "         title=f'Word Frequencies by Topic, Combining the Top {len(lda_top_words_index)} Words in Each Topic')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecf13c",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Coherence scores based on number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ee031",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "coherence_scores = []\n",
    "\n",
    "for n in range(1, 11):\n",
    "    mod = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                          id2word=dictionary,\n",
    "                                          num_topics=n, \n",
    "                                          random_state=117, update_every=1,\n",
    "                                          chunksize=1500, \n",
    "                                          passes=5, iterations=10,\n",
    "                                          alpha='asymmetric', eta=1/100,\n",
    "                                          per_word_topics=True)\n",
    "    cmodel = gensim.models.coherencemodel.CoherenceModel(model=mod,\n",
    "                                                 texts=processed_text,\n",
    "                                                 dictionary=dictionary)\n",
    "    coherence_scores.append((n, cmodel.get_coherence()))\n",
    "    \n",
    "topic_range = [coherence_scores[i][0] for i in range(len(coherence_scores))]\n",
    "cscore = [coherence_scores[i][1] for i in range(len(coherence_scores))]\n",
    "\n",
    "print(f'Coherence scores for the ngram range: {ngram_range} \\n {coherence_scores}')\n",
    "plt.plot(topic_range,cscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
