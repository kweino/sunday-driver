{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a55abdb",
   "metadata": {},
   "source": [
    "# Latent Dirichlet allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8caeb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import re\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from pprint import pprint\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767e5736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4236"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "comments = pd.read_csv('data/comments.csv')[['comments']].dropna().drop_duplicates()\n",
    "len(comments['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "664012ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "\n",
    "STOP_WORDS = STOP_WORDS.union({'ll', 've', 'pron',\n",
    "                               'good','great', 'nice',\n",
    "                               'ride','route','road','rt','roads', 'rode','way'\n",
    "                              })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9701f1",
   "metadata": {},
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "475b2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (2, 3)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=ngram_range,\n",
    "                             stop_words=STOP_WORDS,\n",
    "                            )\n",
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "texts = comments.comments.values.tolist()\n",
    "processed_text = [analyzer(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62824836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 308953\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_text)\n",
    "print('Number of unique tokens: {}'.format(len(dictionary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7218d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(t) for t in processed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef95bf6c",
   "metadata": {},
   "source": [
    "## Initial LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2651ece0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LDA model parameters\n",
    "num_topics = 3\n",
    "num_words = 10\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=num_topics, \n",
    "                                            random_state=17, update_every=1,\n",
    "                                            chunksize=1500, \n",
    "                                            passes=5, iterations=10,\n",
    "                                            alpha='asymmetric', eta=1/100,\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics(num_words=num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_document_topics method shows the topics found \n",
    "# in each corpus doc\n",
    "# i = 0\n",
    "# print(comments.iloc[i], processed_text[i], lda_model.get_document_topics(corpus[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts dominant topic (and percentage) for each comment\n",
    "\n",
    "def get_main_topic_df(model, bow, texts):\n",
    "    topic_list = []\n",
    "    percent_list = []\n",
    "    keyword_list = []\n",
    "    \n",
    "    for wc in bow:\n",
    "        topic, percent = sorted(model.get_document_topics(wc), key=lambda x: x[1], reverse=True)[0]\n",
    "        topic_list.append(topic)\n",
    "        percent_list.append(round(percent, 3))\n",
    "        keyword_list.append(' '.join(sorted([x[0] for x in model.show_topic(topic)])))\n",
    "\n",
    "    result_df = pd.concat([pd.Series(topic_list, name='Dominant_topic'), \n",
    "                           pd.Series(percent_list, name='Percent'), \n",
    "                           pd.Series(texts, name='Processed_text'), \n",
    "                           pd.Series(keyword_list, name='Keywords')], axis=1)\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_topic_df = get_main_topic_df(lda_model, corpus, processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(main_topic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "\n",
    "grouped_topics = main_topic_df.groupby('Dominant_topic')\n",
    "grouped_topics.count()['Processed_text'].\\\n",
    "    plot.bar(rot=0).\\\n",
    "    set(title=f'Dominant Topic Frequency in the {len(comments)} Comments',\n",
    "        ylabel='Topic frequency');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b7758",
   "metadata": {},
   "source": [
    "## Representative data\n",
    "\n",
    "What's the \"most representative\" comment we have in the data for each topic?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2354354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "representatives = pd.DataFrame()\n",
    "\n",
    "for k in grouped_topics.groups.keys():\n",
    "    representatives = pd.concat([ representatives, \n",
    "                                 grouped_topics.get_group(k).sort_values(['Percent'], ascending=False).head(3)])\n",
    "# representatives\n",
    "for i in range(len(representatives)):\n",
    "    print(f'''\n",
    "        Document: {representatives.index[i]}  \n",
    "        Dominant topic: {representatives.loc[representatives.index[i]]['Dominant_topic']}\\n \n",
    "    ''')\n",
    "    print(texts[representatives.index[i]] + '\\n ------- \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fff11e",
   "metadata": {},
   "source": [
    "## Length of documents in each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a654f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_by_topic(topic=0):\n",
    "    d_lens = [len(d) for d in grouped_topics.get_group(topic)['Processed_text']]\n",
    "    plt.hist(d_lens, bins=50)\n",
    "    large = plt.gca().get_ylim()[1]\n",
    "    d_mean = round(np.mean(d_lens), 1)\n",
    "    d_median = np.median(d_lens)\n",
    "    plt.plot([d_mean, d_mean], [0,large], label='Mean = {}'.format(d_mean))\n",
    "    plt.plot([d_median, d_median], [0,large], label='Median = {}'.format(d_median))\n",
    "    plt.legend()\n",
    "    plt.gca().set(xlabel='Document word count', ylabel='Number of documents', xlim=(0, 450), \n",
    "            title='Distribution of Comment Lengths for {} Comments in Topic {}'.format(len(d_lens), topic));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80024ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "slider = IntSlider(min=0, max=num_topics-1, step=1, value=0, description='Topic')\n",
    "interact(word_count_by_topic, topic=slider);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03b247",
   "metadata": {},
   "source": [
    "## Top word distribution per topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e6cff",
   "metadata": {
    "scrolled": false,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "lda_top_words_index = set()\n",
    "for i in range(lda_model.num_topics):\n",
    "    lda_top_words_index = lda_top_words_index.union([k for (k,v) in lda_model.get_topic_terms(i)])\n",
    "\n",
    "#print('Indices of top words: \\n{}\\n'.format(lda_top_words_index))\n",
    "words_we_care_about = [{dictionary[tup[0]]: tup[1] for tup in lst if tup[0] in lda_top_words_index} \n",
    "                       for lst in corpus]\n",
    "lda_top_words_df = pd.DataFrame(words_we_care_about).fillna(0).astype(int).sort_index(axis=1)\n",
    "lda_top_words_df['Cluster'] = main_topic_df['Dominant_topic']\n",
    "(\n",
    "    lda_top_words_df\n",
    "    .groupby('Cluster').sum().transpose()\n",
    "    .plot.bar(figsize=(15, 5), width=0.7,\n",
    "              ylabel='Word frequency',\n",
    "              legend=False,\n",
    "              title=f'Top Word Frequencies in {len(texts)} MR.com Comments',\n",
    "              rot=0\n",
    "             )\n",
    ")\n",
    "# .set(ylabel='Word frequency', \n",
    "#          title=f'Word Frequencies by Topic, Combining the Top {len(lda_top_words_index)} Words in Each Topic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3935df9",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## Coherence scores based on number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3458f44",
   "metadata": {
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "coherence_scores = []\n",
    "\n",
    "for n in range(1, 5):\n",
    "    mod = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                          id2word=dictionary,\n",
    "                                          num_topics=n, \n",
    "                                          random_state=117, update_every=1,\n",
    "                                          chunksize=1500, \n",
    "                                          passes=5, iterations=10,\n",
    "                                          alpha='asymmetric', eta=1/100,\n",
    "                                          per_word_topics=True)\n",
    "    cmodel = gensim.models.coherencemodel.CoherenceModel(model=mod,\n",
    "                                                 texts=processed_text,\n",
    "                                                 dictionary=dictionary)\n",
    "    coherence_scores.append((n, cmodel.get_coherence()))\n",
    "\n",
    "topic_range = [coherence_scores[i][0] for i in range(len(coherence_scores))]\n",
    "cscore = [coherence_scores[i][1] for i in range(len(coherence_scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f1ed88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Coherence scores for the ngram range: {ngram_range} \\n {coherence_scores}')\n",
    "plt.plot(topic_range,cscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9de304",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "- There seem to be 3-4 groups of users making comments on this website.\n",
    "- IF 3:\n",
    "    0. The 'core' group of users make most of the comments.\n",
    "    1. The second group are those who are not as frequent commenters, but when they do post, they usually share videos/links to other sites.\n",
    "    2. The last group do not frequently comment or share videos/links.\n",
    "- IF 4:\n",
    "    0. The 'core' group of users make most of the comments.\n",
    "    1. Post like core group, but less overall. Maybe newer members/budding 'core' group?\n",
    "    2. People riding the tail of the dragon.\n",
    "    3. Other infrequent posters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee2b69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
